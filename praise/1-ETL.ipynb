{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a39f84f-74fe-48db-98e0-0cd26e4e103f",
   "metadata": {},
   "source": [
    "# Extract Transform Load\n",
    "In this notebook, we extract data from the praise worksheet, transform it into suitable, clean data, and load it into the outputs directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35d35c8-fa43-4022-9079-89b29cc10d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849607d6-9d9a-4dc4-853c-fca90c45bf2c",
   "metadata": {},
   "source": [
    "## Total Hours Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1e6558-d5da-4c95-9a5f-a0344fd3943e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Impact Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeptimusq</td>\n",
       "      <td>686.601440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>santigs67</td>\n",
       "      <td>621.789072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ygganderson</td>\n",
       "      <td>502.691508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cranders71</td>\n",
       "      <td>418.671961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sembrestels</td>\n",
       "      <td>380.123299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>solsista</td>\n",
       "      <td>353.034515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>akrtws</td>\n",
       "      <td>332.309293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mzargham</td>\n",
       "      <td>289.446628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iviangita</td>\n",
       "      <td>265.214736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>naynaysoo</td>\n",
       "      <td>251.147051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>durgadasji</td>\n",
       "      <td>223.666299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>metaverde</td>\n",
       "      <td>210.205771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>juankbell</td>\n",
       "      <td>176.099120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mateodaza</td>\n",
       "      <td>174.616627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>griffgreen</td>\n",
       "      <td>173.964135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Handle  Impact Hours\n",
       "0     zeptimusq    686.601440\n",
       "1     santigs67    621.789072\n",
       "2   ygganderson    502.691508\n",
       "3    cranders71    418.671961\n",
       "4   sembrestels    380.123299\n",
       "5      solsista    353.034515\n",
       "6        akrtws    332.309293\n",
       "7      mzargham    289.446628\n",
       "8     iviangita    265.214736\n",
       "9     naynaysoo    251.147051\n",
       "10   durgadasji    223.666299\n",
       "11    metaverde    210.205771\n",
       "12    juankbell    176.099120\n",
       "13    mateodaza    174.616627\n",
       "14   griffgreen    173.964135"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hours = pd.read_excel(\"data/TEC Praise Quantification.xlsx\", sheet_name=\"Total Impact Hours so far\", engine='openpyxl', header=1, index_col=0, usecols=\"A:D\")\n",
    "total_hours = total_hours.reset_index().dropna(thresh=2).reset_index()[['Handle', 'Impact Hours']]\n",
    "total_hours.to_csv('outputs/total_hours.csv', index=False)\n",
    "total_hours.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81b5b4-35f7-404c-9c0f-afbb3297c8b0",
   "metadata": {},
   "source": [
    "## Praise Dataset\n",
    "We consider three batches of praise. Batch one is October 2020, and December2020-May2021. Batch two is prior to December 2020 (other than October). Batch three is after May 7th 2021. Batch one is the original batch that all analysis was performed on. Chronologically, prior to Batch one (batch two) is the early days of praise, and batch 3 is praise that started after the initial praise analysis began."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664246b-6223-4271-abfa-ace7b902cfe9",
   "metadata": {},
   "source": [
    "#### Batch One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7e4e9c-c66c-4f13-92a4-d8d2e57a1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [\n",
    "    \"#17 May 7\",\n",
    "    \"#16 Apr 24\",\n",
    "    \"#15 Apr 9\",\n",
    "    \"#14 Mar 26\",\n",
    "    \"#13 Mar 12\",\n",
    "    \"#12 Feb 26\",\n",
    "    \"#11 Feb 12\",\n",
    "    \"#10 Jan 29\",\n",
    "    \"#9 Jan 15\", \n",
    "    \"#8 Jan 1\",\n",
    "    \"#7 Dec 18\",\n",
    "    \"#6 Dec 4\",\n",
    "    \"#2 Oct 9\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed32d96-c145-4f57-a84f-bdb8d89b0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_period_from_sheet(period: str, batch: str) -> pd.DataFrame:\n",
    "        # Load the data\n",
    "        df = pd.read_excel('data/TEC Praise Quantification.xlsx', skiprows=2, sheet_name=period,engine='openpyxl', usecols=\"A:M\")\n",
    "        \n",
    "        # Add a period column\n",
    "        df['period'] = period\n",
    "        df['batch'] = batch\n",
    "        \n",
    "        # Remove the validator normalization as it is confusing and unecessary for analysis\n",
    "        df.columns = list(df.columns[:6]) + ['v1 norm', 'v2 norm', 'v3 norm'] + list(df.columns[9:])\n",
    "        df = df.dropna(thresh=8).drop(['v1 norm', 'v2 norm', 'v3 norm'], axis=1)\n",
    "        \n",
    "        # Return the loaded df\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac21b5fa-747b-46ac-bb5b-b4ef7f0e3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate data\n",
    "data = pd.concat([read_period_from_sheet(p, batch='Batch 1') for p in periods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc35ed3-4743-41fe-b8f3-375e56a1ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these duplicate columns and drop the lesser named one.\n",
    "df = data.copy()\n",
    "# To\n",
    "df['To'] = df['To'].combine_first(df['To.1']).combine_first(df['Unnamed: 12'])\n",
    "df = df.drop(['To.1', 'Unnamed: 12'], axis=1)\n",
    "\n",
    "# IH Per Praise\n",
    "df['IH per Praise'] = df['IH per Praise'].combine_first(df['Cred per Praise'])\n",
    "df = df.drop('Cred per Praise', axis=1)\n",
    "\n",
    "# IH Per Person Per Period\n",
    "df['IH per person'] = df['IH per person'].combine_first(df['Cred per person'])\n",
    "df = df.drop('Cred per person', axis=1)\n",
    "\n",
    "# Rename The Institution Column\n",
    "df = df.rename({'Unnamed: 3':'Institution'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f59fbd-36b6-4aa0-ab37-a413c05050a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>From</th>\n",
       "      <th>Reason for dishing</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Date</th>\n",
       "      <th>Room</th>\n",
       "      <th>Avg %</th>\n",
       "      <th>IH per Praise</th>\n",
       "      <th>IH per person</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>batch</th>\n",
       "      <th>Cred per Praise</th>\n",
       "      <th>Cred per person</th>\n",
       "      <th>To.1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#10 Jan 29</th>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>573</td>\n",
       "      <td>569</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#11 Feb 12</th>\n",
       "      <td>463</td>\n",
       "      <td>463</td>\n",
       "      <td>463</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>463</td>\n",
       "      <td>454</td>\n",
       "      <td>463</td>\n",
       "      <td>422</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#12 Feb 26</th>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>646</td>\n",
       "      <td>646</td>\n",
       "      <td>646</td>\n",
       "      <td>662</td>\n",
       "      <td>657</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#13 Mar 12</th>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>624</td>\n",
       "      <td>624</td>\n",
       "      <td>624</td>\n",
       "      <td>651</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#14 Mar 26</th>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>774</td>\n",
       "      <td>774</td>\n",
       "      <td>774</td>\n",
       "      <td>804</td>\n",
       "      <td>797</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#15 Apr 9</th>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#16 Apr 24</th>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>908</td>\n",
       "      <td>905</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#17 May 7</th>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "      <td>974</td>\n",
       "      <td>971</td>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#2 Oct 9</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#6 Dec 4</th>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#7 Dec 18</th>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>478</td>\n",
       "      <td>476</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#8 Jan 1</th>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "      <td>357</td>\n",
       "      <td>355</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#9 Jan 15</th>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>566</td>\n",
       "      <td>587</td>\n",
       "      <td>587</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             To  From  Reason for dishing  Unnamed: 3  Date  Room  Avg %  \\\n",
       "period                                                                     \n",
       "#10 Jan 29  575   575                 575         552   552   552    573   \n",
       "#11 Feb 12  463   463                 463         438   438   438    463   \n",
       "#12 Feb 26  672   672                 672         646   646   646    662   \n",
       "#13 Mar 12  651   651                 651         624   624   624    651   \n",
       "#14 Mar 26  804   804                 804         774   774   774    804   \n",
       "#15 Apr 9   963   963                 963         932   932   932    963   \n",
       "#16 Apr 24  908   908                 908         875   875   875    908   \n",
       "#17 May 7   974   974                 974         940   940   940    974   \n",
       "#2 Oct 9    124   124                 124         124   124   124    124   \n",
       "#6 Dec 4    509   509                 509         490   490   490    509   \n",
       "#7 Dec 18   479   479                 479         457   457   457    478   \n",
       "#8 Jan 1    358   358                 358         336   336   336    357   \n",
       "#9 Jan 15   589   589                 589         566   566   566    587   \n",
       "\n",
       "            IH per Praise  IH per person  Unnamed: 12  batch  Cred per Praise  \\\n",
       "period                                                                          \n",
       "#10 Jan 29            569            575          575    575                0   \n",
       "#11 Feb 12            454            463          422    463                0   \n",
       "#12 Feb 26            657            672          672    672                0   \n",
       "#13 Mar 12            649            651          651    651                0   \n",
       "#14 Mar 26            797            804          804    804                0   \n",
       "#15 Apr 9             963            963          963    963                0   \n",
       "#16 Apr 24            905            908          908    908                0   \n",
       "#17 May 7             971            974          974    974                0   \n",
       "#2 Oct 9                0              0            0    124              124   \n",
       "#6 Dec 4                0              0          509    509              509   \n",
       "#7 Dec 18             476            479          479    479                0   \n",
       "#8 Jan 1              355            358          358    358                0   \n",
       "#9 Jan 15             587            589          589    589                0   \n",
       "\n",
       "            Cred per person  To.1  \n",
       "period                             \n",
       "#10 Jan 29                0     0  \n",
       "#11 Feb 12                0     0  \n",
       "#12 Feb 26                0     0  \n",
       "#13 Mar 12                0     0  \n",
       "#14 Mar 26                0     0  \n",
       "#15 Apr 9                 0     0  \n",
       "#16 Apr 24                0     0  \n",
       "#17 May 7                 0     0  \n",
       "#2 Oct 9                124   124  \n",
       "#6 Dec 4                509     0  \n",
       "#7 Dec 18                 0     0  \n",
       "#8 Jan 1                  0     0  \n",
       "#9 Jan 15                 0     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('period').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add775d-72a3-4af1-beab-da6942402ca2",
   "metadata": {},
   "source": [
    "#### Batch Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cd7a0f-01aa-42d1-b5fd-aeb43b203c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>From</th>\n",
       "      <th>Reason for dishing</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Date</th>\n",
       "      <th>Room</th>\n",
       "      <th>Avg %</th>\n",
       "      <th>IH per Praise</th>\n",
       "      <th>IH per person</th>\n",
       "      <th>period</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeptimusQ</td>\n",
       "      <td>Tam2140#9361</td>\n",
       "      <td>for hosting this kicking params party!</td>\n",
       "      <td>Token Engineering Commons</td>\n",
       "      <td>May-07-2021</td>\n",
       "      <td>🙏praise</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>2.355252</td>\n",
       "      <td>39.04072</td>\n",
       "      <td>#17 May 7</td>\n",
       "      <td>Batch 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          To          From                       Reason for dishing  \\\n",
       "0  zeptimusQ  Tam2140#9361  for hosting this kicking params party!    \n",
       "\n",
       "                 Institution         Date     Room     Avg %  IH per Praise  \\\n",
       "0  Token Engineering Commons  May-07-2021  🙏praise  0.001963       2.355252   \n",
       "\n",
       "   IH per person     period    batch  \n",
       "0       39.04072  #17 May 7  Batch 1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c53be68-b6a3-4f33-b423-c9d256b2b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [\n",
    "    \"#5 Nov 20\", \n",
    "    \"#4 Nov 6\", \n",
    "    \"#3 Oct 23\", \n",
    "    \"#1 Sept 24\", \n",
    "    \"#0 Sept 7 (historic)\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b83fe8-fd71-4835-8c57-de2b6f6a4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([read_period_from_sheet(p, batch='Batch 2') for p in periods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "200493db-3b75-4d39-8b19-0d8bd7bda20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these duplicate columns and drop the lesser named one.\n",
    "df2 = data2.copy()\n",
    "# To\n",
    "df2['To'] = df2['To'].combine_first(df2['To.1'])\n",
    "df2 = df2.drop(['To.1'], axis=1)\n",
    "\n",
    "# IH Per Praise\n",
    "df2 = df2.rename({'Cred per Praise':'IH per Praise'}, axis=1)\n",
    "\n",
    "# IH Per Person Per Period\n",
    "df2 = df2.rename({'Cred per person':'IH per person'}, axis=1)\n",
    "\n",
    "# Rename The Institution Column\n",
    "df2 = df2.rename({'Unnamed: 3':'Institution'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60687e-0fde-4ee4-8687-6efbd590ce0d",
   "metadata": {},
   "source": [
    "#### Batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6322da72-3a51-405d-9253-8d85ab73651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [\n",
    "    \"#18 May 21\",\n",
    "    \"#19 Jun 4\",\n",
    "    \"#20 Jun 18\",\n",
    "    \"#21 July 1\",\n",
    "    \"#22 July 11\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef479abd-5b83-4350-a490-b6fb60de1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.concat([read_period_from_sheet(p, batch='Batch 3') for p in periods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db1c589-67d2-45ab-8c1a-34030d685c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these duplicate columns and drop the lesser named one.\n",
    "df3 = data3.copy()\n",
    "# To\n",
    "df3['To'] = df3['To'].combine_first(df3['Unnamed: 12'])\n",
    "df3 = df3.drop(['Unnamed: 12'], axis=1)\n",
    "\n",
    "# Rename The Institution Column\n",
    "df3 = df3.rename({'Unnamed: 3':'Institution'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da23a2-b449-49f3-bcba-c2011ce32f23",
   "metadata": {},
   "source": [
    "### Concatenate Praise Batches into Praise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aea094ef-3b0e-49eb-baf9-6ffce7fffaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df, df2, df3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d8e72-a52a-4eeb-babd-535e584731d0",
   "metadata": {},
   "source": [
    "### Resolving Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ae45d7-5d15-43b8-9d0e-7d4dde9dc971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are still missing 10 names\n"
     ]
    }
   ],
   "source": [
    "names_df = pd.read_excel('data/TEC Praise Quantification.xlsx',sheet_name=\"DO NOT TOUCH Imported\",engine='openpyxl', usecols=\"A:D\")\n",
    "\n",
    "#### We create a dictionary that matches each non-null entry in the spreadsheet to its \"IH & CSTK Handle\"\n",
    "source_cols = names_df.columns\n",
    "names_dict = {} #create a blank dictionary\n",
    "\n",
    "for i in range(len(names_df)):\n",
    "    for col in source_cols:\n",
    "        name_to_consider = names_df.loc[i, col]\n",
    "        canonical_name = names_df.loc[i,\"IH & CSTK Handle\"]\n",
    "        if pd.isna(canonical_name):\n",
    "            canonical_name = name_to_consider\n",
    "        if not(pd.isna(name_to_consider)):\n",
    "            names_dict[name_to_consider] = canonical_name\n",
    "\n",
    "#### Did we catch them all? See if there's anything in the combned user sets of \"To\" and \"From\" that isn't a key in the names_dict dictionary. \n",
    "combined_users = set([]).union(set(data[\"From\"]),set(data[\"To\"]))\n",
    "names_uncaught = sorted([str(x) for x in combined_users if (not(x in names_dict.keys()) and not(pd.isna(x)))])\n",
    "\n",
    "# print(\"All told, there are {} names in our data set that lack canonical representations: \\n\".format(str(len(names_uncaught))))\n",
    "# print(\"We do not have canonical representations for the following names: \\n\")\n",
    "# for name in names_uncaught:\n",
    "#     print(str(name))\n",
    "\n",
    "def clean_name(name):\n",
    "    new_name = str(name)\n",
    "    new_name = new_name.lower()\n",
    "    new_name = re.sub('#\\d\\d\\d\\d','',new_name)\n",
    "    new_name = re.sub('[^A-Za-z0-9]+', '', new_name) #remove all non-alphanumeric characters\n",
    "    return new_name\n",
    "\n",
    "clean_name(\"zeptimusQ\")\n",
    "clean_name(\"ygg_anderson\")\n",
    "clean_name(\"AmwFund#0979\")\n",
    "clean_name(\"Caeser (PST)#0046\")\n",
    "\n",
    "cleaned_keys = []\n",
    "original_keys = list(names_dict.keys())\n",
    "for key in original_keys:\n",
    "    clean_key = clean_name(key)\n",
    "    cleaned_keys.append(clean_key)\n",
    "    if not(clean_key == key):\n",
    "        names_dict[clean_key] = names_dict[key]\n",
    "    \n",
    "new_pairs = {}\n",
    "\n",
    "for name in names_uncaught:\n",
    "    clean_version = clean_name(name) #clean the name \n",
    "    key_matches = [key for key in cleaned_keys if clean_version == key] #make a list of all keys with same cleaned name\n",
    "    if len(key_matches) > 0:\n",
    "        for match in key_matches:\n",
    "            if match in names_dict.keys():\n",
    "                right_name = names_dict[match]\n",
    "                new_pairs[name] = right_name\n",
    "                names_dict[name] = right_name\n",
    "                break\n",
    "                    \n",
    "# print(\"We were able to add the following names: \\n\")\n",
    "# for name in new_pairs.keys():\n",
    "#     print(str(name) + \"\\t ----> \\t\" + str(names_dict[name]))\n",
    "\n",
    "still_uncaught_names = sorted([str(x) for x in combined_users if (not(x in names_dict.keys()))])\n",
    "num_still_uncaught_names = str(len(still_uncaught_names))\n",
    "print(\"We are still missing {} names\".format(num_still_uncaught_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b1326cf-ddaf-4d9a-b150-f3bf21673356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 remaining users with no representation.\n",
      "These users are \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def total_appearances(name, data):\n",
    "    from_appearances = sum(data[\"From\"] == name)\n",
    "    to_appearances = sum(data[\"To\"] == name)\n",
    "    total = from_appearances + to_appearances\n",
    "    return total \n",
    "\n",
    "still_uncaught_appearances = [total_appearances(x, data) for x in still_uncaught_names]\n",
    "\n",
    "uncaught_df = pd.DataFrame({\"name\": still_uncaught_names, \"appearances\" : still_uncaught_appearances})\n",
    "\n",
    "for name in still_uncaught_names:\n",
    "    names_dict[name] = name\n",
    "\n",
    "last_remaining = [user for user in combined_users if(not(user in names_dict.keys()))]\n",
    "num_remaining = len(last_remaining)\n",
    "print(\"There are {} remaining users with no representation.\".format(num_remaining))\n",
    "print(\"These users are \\n\")\n",
    "\n",
    "for name in last_remaining:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd23ba7d-8d94-41f4-9a6f-9b1e3be6abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1767fac7-5899-42ad-8b02-e066b8f5a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outputs/names_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(names_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc049a9-7bc0-4cca-91bd-f5934cfee6e5",
   "metadata": {},
   "source": [
    "Map the names in the dataframe to the resolved names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d512c86a-e41f-4912-b7f7-8e593a0de4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,\"To\"] = data.loc[:,\"To\"].map(names_dict)\n",
    "data.loc[:, \"From\"] = data.loc[:,\"From\"].map(names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df313c-2054-4e89-b9d8-e62ec05039d3",
   "metadata": {},
   "source": [
    "### Save Cleaned Praise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ea347c4-50df-4948-9fc6-4b7489ee3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('outputs/praise_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99181faf-d519-4e9c-b9a7-0fa0e87eb799",
   "metadata": {},
   "source": [
    "### Split Receivers and Quantifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f07a885-61f1-4fcf-8476-361472d9f606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receivers = data[(~data[['Institution', 'Date', 'Room']].isna().all(axis=1)) & (data['From'] != 'Quantifiers')]\n",
    "quantifiers = data[(data[['Institution', 'Date', 'Room']].isna().all(axis=1)) | (data['From'] == 'Quantifiers')]\n",
    "len(receivers) + len(quantifiers) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83fcc927-4ca1-4f0a-a3af-3450bf3928f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "receivers.to_csv('outputs/receivers.csv', index=False)\n",
    "quantifiers.to_csv('outputs/quantifiers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0942ca34-01ad-4814-831a-9e6c62c464c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#17 May 7', '#16 Apr 24', '#15 Apr 9', '#14 Mar 26', '#13 Mar 12',\n",
       "       '#12 Feb 26', '#11 Feb 12', '#10 Jan 29', '#9 Jan 15', '#8 Jan 1',\n",
       "       '#7 Dec 18', '#6 Dec 4', '#2 Oct 9', '#5 Nov 20', '#4 Nov 6',\n",
       "       '#3 Oct 23', '#1 Sept 24', '#0 Sept 7 (historic)', '#18 May 21',\n",
       "       '#19 Jun 4', '#20 Jun 18', '#21 July 1', '#22 July 11'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['period'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1579ee4-3cc0-459b-87ee-2636af494e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To</th>\n",
       "      <th>From</th>\n",
       "      <th>Reason for dishing</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Date</th>\n",
       "      <th>Room</th>\n",
       "      <th>Avg %</th>\n",
       "      <th>IH per Praise</th>\n",
       "      <th>IH per person</th>\n",
       "      <th>period</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeptimusQ</td>\n",
       "      <td>Tam2140</td>\n",
       "      <td>for hosting this kicking params party!</td>\n",
       "      <td>Token Engineering Commons</td>\n",
       "      <td>May-07-2021</td>\n",
       "      <td>🙏praise</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>2.355252</td>\n",
       "      <td>39.040720</td>\n",
       "      <td>#17 May 7</td>\n",
       "      <td>Batch 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zeptimusQ</td>\n",
       "      <td>iviangita</td>\n",
       "      <td>for hosting and leading a lot of params parties</td>\n",
       "      <td>Token Engineering Commons</td>\n",
       "      <td>May-07-2021</td>\n",
       "      <td>🙏praise</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>1.995539</td>\n",
       "      <td>39.040720</td>\n",
       "      <td>#17 May 7</td>\n",
       "      <td>Batch 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zeptimusQ</td>\n",
       "      <td>JuankBell</td>\n",
       "      <td>for testing and deploying the bot to record an...</td>\n",
       "      <td>Token Engineering Commons</td>\n",
       "      <td>Apr-28-2021</td>\n",
       "      <td>🙏praise</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>1.610872</td>\n",
       "      <td>39.040720</td>\n",
       "      <td>#17 May 7</td>\n",
       "      <td>Batch 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zeptimusQ</td>\n",
       "      <td>iviangita</td>\n",
       "      <td>for the huge success of the MVV process</td>\n",
       "      <td>Token Engineering Commons</td>\n",
       "      <td>Apr-30-2021</td>\n",
       "      <td>🙏praise</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>1.251160</td>\n",
       "      <td>39.040720</td>\n",
       "      <td>#17 May 7</td>\n",
       "      <td>Batch 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zeptimusQ</td>\n",
       "      <td>iviangita</td>\n",
       "      <td>for his awesome work on the recorder bot, for ...</td>\n",
       "      <td>Token Engineering Commons</td>\n",
       "      <td>Apr-30-2021</td>\n",
       "      <td>🙏praise</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>1.251160</td>\n",
       "      <td>39.040720</td>\n",
       "      <td>#17 May 7</td>\n",
       "      <td>Batch 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>andythegreenie#7463</td>\n",
       "      <td>iviangita</td>\n",
       "      <td>for mentioning or retweeting Commons Stack on ...</td>\n",
       "      <td>Commons Stack</td>\n",
       "      <td>2021-07-02 00:00:00</td>\n",
       "      <td>🙌praise</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.410317</td>\n",
       "      <td>0.410317</td>\n",
       "      <td>#22 July 11</td>\n",
       "      <td>Batch 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>kei#9866</td>\n",
       "      <td>iviangita</td>\n",
       "      <td>@David (please DYOR...) @KZ Flyer for mentioni...</td>\n",
       "      <td>Commons Stack</td>\n",
       "      <td>2021-07-11 00:00:00</td>\n",
       "      <td>🙌praise</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.410317</td>\n",
       "      <td>0.410317</td>\n",
       "      <td>#22 July 11</td>\n",
       "      <td>Batch 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>lefterisjp</td>\n",
       "      <td>iviangita</td>\n",
       "      <td>@lefterisjp | Rotki for mentioning or retweeti...</td>\n",
       "      <td>Commons Stack</td>\n",
       "      <td>2021-07-11 00:00:00</td>\n",
       "      <td>🙌praise</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.410317</td>\n",
       "      <td>0.410317</td>\n",
       "      <td>#22 July 11</td>\n",
       "      <td>Batch 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>fabiosmendes</td>\n",
       "      <td>Quantifiers</td>\n",
       "      <td>Gets paid from General Magic so he gets 50% of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>#22 July 11</td>\n",
       "      <td>Batch 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>geleeroyale</td>\n",
       "      <td>Quantifiers</td>\n",
       "      <td>Gets paid by the Giveth so he only get 50% IH,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>#22 July 11</td>\n",
       "      <td>Batch 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13915 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       To         From  \\\n",
       "0               zeptimusQ      Tam2140   \n",
       "1               zeptimusQ    iviangita   \n",
       "2               zeptimusQ    JuankBell   \n",
       "3               zeptimusQ    iviangita   \n",
       "4               zeptimusQ    iviangita   \n",
       "...                   ...          ...   \n",
       "1129  andythegreenie#7463    iviangita   \n",
       "1130             kei#9866    iviangita   \n",
       "1131           lefterisjp    iviangita   \n",
       "1132         fabiosmendes  Quantifiers   \n",
       "1133          geleeroyale  Quantifiers   \n",
       "\n",
       "                                     Reason for dishing  \\\n",
       "0               for hosting this kicking params party!    \n",
       "1      for hosting and leading a lot of params parties    \n",
       "2     for testing and deploying the bot to record an...   \n",
       "3              for the huge success of the MVV process    \n",
       "4     for his awesome work on the recorder bot, for ...   \n",
       "...                                                 ...   \n",
       "1129  for mentioning or retweeting Commons Stack on ...   \n",
       "1130  @David (please DYOR...) @KZ Flyer for mentioni...   \n",
       "1131  @lefterisjp | Rotki for mentioning or retweeti...   \n",
       "1132  Gets paid from General Magic so he gets 50% of...   \n",
       "1133  Gets paid by the Giveth so he only get 50% IH,...   \n",
       "\n",
       "                    Institution                 Date     Room     Avg %  \\\n",
       "0     Token Engineering Commons          May-07-2021  🙏praise  0.001963   \n",
       "1     Token Engineering Commons          May-07-2021  🙏praise  0.001663   \n",
       "2     Token Engineering Commons          Apr-28-2021  🙏praise  0.001342   \n",
       "3     Token Engineering Commons          Apr-30-2021  🙏praise  0.001043   \n",
       "4     Token Engineering Commons          Apr-30-2021  🙏praise  0.001043   \n",
       "...                         ...                  ...      ...       ...   \n",
       "1129              Commons Stack  2021-07-02 00:00:00  🙌praise  0.000205   \n",
       "1130              Commons Stack  2021-07-11 00:00:00  🙌praise  0.000205   \n",
       "1131              Commons Stack  2021-07-11 00:00:00  🙌praise  0.000205   \n",
       "1132                        NaN                  NaN      NaN  0.000000   \n",
       "1133                        NaN                  NaN      NaN  0.000000   \n",
       "\n",
       "      IH per Praise  IH per person       period    batch  \n",
       "0          2.355252      39.040720    #17 May 7  Batch 1  \n",
       "1          1.995539      39.040720    #17 May 7  Batch 1  \n",
       "2          1.610872      39.040720    #17 May 7  Batch 1  \n",
       "3          1.251160      39.040720    #17 May 7  Batch 1  \n",
       "4          1.251160      39.040720    #17 May 7  Batch 1  \n",
       "...             ...            ...          ...      ...  \n",
       "1129       0.410317       0.410317  #22 July 11  Batch 3  \n",
       "1130       0.410317       0.410317  #22 July 11  Batch 3  \n",
       "1131       0.410317       0.410317  #22 July 11  Batch 3  \n",
       "1132       0.000000       0.000000  #22 July 11  Batch 3  \n",
       "1133       0.000000       0.000000  #22 July 11  Batch 3  \n",
       "\n",
       "[13915 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86deae-2b18-442e-b139-a49e309c62ec",
   "metadata": {},
   "source": [
    "# Audit Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "375b4b21-bcbe-41c9-8c8a-0be05fff9cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_excel(\"data/TEC Praise Quantification.xlsx\", sheet_name=\"Deduction Audit Results\", engine='openpyxl', header=1, usecols=\"A:D\")\n",
    "results.to_csv('outputs/audit_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07f2a961-edc1-4cf4-a447-783aff2aa594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Impact Hours Calc</th>\n",
       "      <th>Impact Hours Calc.1</th>\n",
       "      <th>Why?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naynaysoo</td>\n",
       "      <td>125.868000</td>\n",
       "      <td>125.868000</td>\n",
       "      <td>Was deducted but not paid for several months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freedumbs00</td>\n",
       "      <td>73.345850</td>\n",
       "      <td>73.345850</td>\n",
       "      <td>Was deducted but not paid for several months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fabiosmendes</td>\n",
       "      <td>10.639598</td>\n",
       "      <td>10.639598</td>\n",
       "      <td>Was deducted more than he should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fabimol</td>\n",
       "      <td>9.260812</td>\n",
       "      <td>9.260812</td>\n",
       "      <td>Was deducted but not paid for several months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geleeroyale</td>\n",
       "      <td>5.867313</td>\n",
       "      <td>5.867313</td>\n",
       "      <td>Was deducted but not paid for several months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jeffemmett</td>\n",
       "      <td>4.397127</td>\n",
       "      <td>4.397127</td>\n",
       "      <td>Was deducted more than he should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gfriis</td>\n",
       "      <td>3.100002</td>\n",
       "      <td>3.100002</td>\n",
       "      <td>Was deducted more than he should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vivszaid</td>\n",
       "      <td>1.683976</td>\n",
       "      <td>1.683976</td>\n",
       "      <td>Was deducted more than she should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vegayp</td>\n",
       "      <td>1.470148</td>\n",
       "      <td>1.470148</td>\n",
       "      <td>Was deducted more than he should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iviangita</td>\n",
       "      <td>1.368500</td>\n",
       "      <td>1.368500</td>\n",
       "      <td>Was deducted more than she should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ekeneodigwe#1502</td>\n",
       "      <td>1.152142</td>\n",
       "      <td>1.152142</td>\n",
       "      <td>Was deducted more than he should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>katalenacaban</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>Was deducted more than she should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Anthonyoliai</td>\n",
       "      <td>0.621750</td>\n",
       "      <td>0.621750</td>\n",
       "      <td>Was deducted more than she should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fiorebotta</td>\n",
       "      <td>0.498438</td>\n",
       "      <td>0.498438</td>\n",
       "      <td>Was deducted more than she should have been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>atacas</td>\n",
       "      <td>-0.579500</td>\n",
       "      <td>-0.579500</td>\n",
       "      <td>Was paid by Commons Stack but not deducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vitormarthendal</td>\n",
       "      <td>-1.139250</td>\n",
       "      <td>-1.139250</td>\n",
       "      <td>Was paid by General Magic but not deducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>krisjones</td>\n",
       "      <td>-1.169325</td>\n",
       "      <td>-1.169325</td>\n",
       "      <td>Was paid by Commons Stack but not deducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vyvy-vi#5040</td>\n",
       "      <td>-1.339918</td>\n",
       "      <td>-1.339918</td>\n",
       "      <td>Was paid by Commons Stack but not deducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xgabi</td>\n",
       "      <td>-1.473682</td>\n",
       "      <td>-1.473682</td>\n",
       "      <td>Was paid by Commons Stack but not deducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ygganderson</td>\n",
       "      <td>-1.985445</td>\n",
       "      <td>-1.985445</td>\n",
       "      <td>COMPLICATED! Check the sheet: https://docs.goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nikoline_nik</td>\n",
       "      <td>-3.113000</td>\n",
       "      <td>-3.113000</td>\n",
       "      <td>Was paid by Commons Stack but not deducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sgonzt</td>\n",
       "      <td>-5.091250</td>\n",
       "      <td>-5.091250</td>\n",
       "      <td>Was paid by Commons Stack but not deducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>heater03</td>\n",
       "      <td>-6.535500</td>\n",
       "      <td>-6.535500</td>\n",
       "      <td>Was paid by Commons Stack but not deducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>merlinegalite</td>\n",
       "      <td>-8.616369</td>\n",
       "      <td>-8.616369</td>\n",
       "      <td>Was paid by Giveth but not deducted for many m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mount Manu#3530</td>\n",
       "      <td>-8.617805</td>\n",
       "      <td>-8.617805</td>\n",
       "      <td>Was paid by Giveth but not deducted for June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Danibelle</td>\n",
       "      <td>-9.198939</td>\n",
       "      <td>-9.198939</td>\n",
       "      <td>Was paid by Giveth but not deducted for many m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>knobsDAO</td>\n",
       "      <td>-9.552509</td>\n",
       "      <td>-9.552509</td>\n",
       "      <td>Was paid by Commons Stack but not deducted for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kristoferkristofer</td>\n",
       "      <td>-11.628058</td>\n",
       "      <td>-11.628058</td>\n",
       "      <td>Was paid by Commons Stack but not deducted for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>divine_comedian</td>\n",
       "      <td>-13.649700</td>\n",
       "      <td>-13.649700</td>\n",
       "      <td>Was paid by Giveth but not deducted for many m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>laurenluz</td>\n",
       "      <td>-19.550750</td>\n",
       "      <td>-19.550750</td>\n",
       "      <td>Was paid by Giveth but not deducted for many m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Suga#8514</td>\n",
       "      <td>-43.969702</td>\n",
       "      <td>-43.969702</td>\n",
       "      <td>Was paid by Commons Stack but not deducted for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mateodaza</td>\n",
       "      <td>-67.556792</td>\n",
       "      <td>-67.556792</td>\n",
       "      <td>Was paid by Giveth but not deducted for many m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Handle  Impact Hours Calc  Impact Hours Calc.1  \\\n",
       "0            naynaysoo         125.868000           125.868000   \n",
       "1          freedumbs00          73.345850            73.345850   \n",
       "2         fabiosmendes          10.639598            10.639598   \n",
       "3              fabimol           9.260812             9.260812   \n",
       "4          geleeroyale           5.867313             5.867313   \n",
       "5           jeffemmett           4.397127             4.397127   \n",
       "6               Gfriis           3.100002             3.100002   \n",
       "7             vivszaid           1.683976             1.683976   \n",
       "8               vegayp           1.470148             1.470148   \n",
       "9            iviangita           1.368500             1.368500   \n",
       "10    Ekeneodigwe#1502           1.152142             1.152142   \n",
       "11       katalenacaban           0.932500             0.932500   \n",
       "12        Anthonyoliai           0.621750             0.621750   \n",
       "13          fiorebotta           0.498438             0.498438   \n",
       "14              atacas          -0.579500            -0.579500   \n",
       "15     vitormarthendal          -1.139250            -1.139250   \n",
       "16           krisjones          -1.169325            -1.169325   \n",
       "17        Vyvy-vi#5040          -1.339918            -1.339918   \n",
       "18               xgabi          -1.473682            -1.473682   \n",
       "19         ygganderson          -1.985445            -1.985445   \n",
       "20        nikoline_nik          -3.113000            -3.113000   \n",
       "21              sgonzt          -5.091250            -5.091250   \n",
       "22            heater03          -6.535500            -6.535500   \n",
       "23       merlinegalite          -8.616369            -8.616369   \n",
       "24     Mount Manu#3530          -8.617805            -8.617805   \n",
       "25           Danibelle          -9.198939            -9.198939   \n",
       "26            knobsDAO          -9.552509            -9.552509   \n",
       "27  kristoferkristofer         -11.628058           -11.628058   \n",
       "28     divine_comedian         -13.649700           -13.649700   \n",
       "29           laurenluz         -19.550750           -19.550750   \n",
       "30           Suga#8514         -43.969702           -43.969702   \n",
       "31           mateodaza         -67.556792           -67.556792   \n",
       "\n",
       "                                                 Why?  \n",
       "0        Was deducted but not paid for several months  \n",
       "1        Was deducted but not paid for several months  \n",
       "2         Was deducted more than he should have been   \n",
       "3        Was deducted but not paid for several months  \n",
       "4        Was deducted but not paid for several months  \n",
       "5         Was deducted more than he should have been   \n",
       "6         Was deducted more than he should have been   \n",
       "7        Was deducted more than she should have been   \n",
       "8         Was deducted more than he should have been   \n",
       "9        Was deducted more than she should have been   \n",
       "10        Was deducted more than he should have been   \n",
       "11       Was deducted more than she should have been   \n",
       "12       Was deducted more than she should have been   \n",
       "13       Was deducted more than she should have been   \n",
       "14         Was paid by Commons Stack but not deducted  \n",
       "15         Was paid by General Magic but not deducted  \n",
       "16        Was paid by Commons Stack but not deducted   \n",
       "17        Was paid by Commons Stack but not deducted   \n",
       "18        Was paid by Commons Stack but not deducted   \n",
       "19  COMPLICATED! Check the sheet: https://docs.goo...  \n",
       "20        Was paid by Commons Stack but not deducted   \n",
       "21        Was paid by Commons Stack but not deducted   \n",
       "22        Was paid by Commons Stack but not deducted   \n",
       "23  Was paid by Giveth but not deducted for many m...  \n",
       "24       Was paid by Giveth but not deducted for June  \n",
       "25  Was paid by Giveth but not deducted for many m...  \n",
       "26  Was paid by Commons Stack but not deducted for...  \n",
       "27  Was paid by Commons Stack but not deducted for...  \n",
       "28  Was paid by Giveth but not deducted for many m...  \n",
       "29  Was paid by Giveth but not deducted for many m...  \n",
       "30  Was paid by Commons Stack but not deducted for...  \n",
       "31  Was paid by Giveth but not deducted for many m...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578897d-4a61-4acd-a020-eb64726652f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
